{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Identificación De Especies de Mosquitos - Data Science**\n",
    "\n",
    "Carol Arévalo, Stefano Aragoni, Luis Santos, Diego Perdomo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modelo*\n",
    "\n",
    "El Ministerio de Salud y Asistencia Social (MSPAS) ha informado que Guatemala ha experimentado un aumento significativo en el número de casos de dengue en 2023, con más de 10,000 casos confirmados y 21 muertes hasta el 12 de agosto. El MSPAS ha declarado una alerta epidemiológica en todo el país para combatir la propagación del dengue (Gobierno De Guatemala, 2023).  \n",
    "\n",
    "\n",
    "Con esto en mente, el presente proyecto busca utilizar técnicas de procesamiento de imágenes y aprendizaje automático para identificar la especie de mosquito Aedes aegypti a partir de imágenes, con el fin de apoyar los esfuerzos de prevención del dengue en Guatemala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías\n",
    "\n",
    "Como primer paso, se importan las librerías necesarias para el desarrollo del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Conv2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargas las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('phase2_train_v0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analizar la Distribución de Clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albopictus            4612\n",
      "culex                 4563\n",
      "culiseta               622\n",
      "japonicus/koreicus     429\n",
      "anopheles               84\n",
      "aegypti                 47\n",
      "Name: class_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver la distribución de las clases\n",
    "class_distribution = data['class_label'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estandarización de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3157: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carev\\OneDrive\\Documentos\\GitHub\\proyecto_dataScience\\modelo.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carev/OneDrive/Documentos/GitHub/proyecto_dataScience/modelo.ipynb#Y145sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_folder, filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carev/OneDrive/Documentos/GitHub/proyecto_dataScience/modelo.ipynb#Y145sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carev/OneDrive/Documentos/GitHub/proyecto_dataScience/modelo.ipynb#Y145sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mcrop((row\u001b[39m.\u001b[39;49mbbx_xtl, row\u001b[39m.\u001b[39;49mbbx_ytl, row\u001b[39m.\u001b[39;49mbbx_xbr, row\u001b[39m.\u001b[39;49mbbx_ybr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carev/OneDrive/Documentos/GitHub/proyecto_dataScience/modelo.ipynb#Y145sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mresize((target_width, target_height), Image\u001b[39m.\u001b[39mLANCZOS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carev/OneDrive/Documentos/GitHub/proyecto_dataScience/modelo.ipynb#Y145sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Convertir la imagen a escala de grises\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:1206\u001b[0m, in \u001b[0;36mImage.crop\u001b[1;34m(self, box)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCoordinate \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is less than \u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 1206\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_crop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim, box))\n",
      "File \u001b[1;32mc:\\Users\\carev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = 'final'\n",
    "output_folder = 'procesadas'\n",
    "\n",
    "# 1. Crea la carpeta de salida si no existe\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 2. Recorte, redimensionado y normalización\n",
    "target_width = 100\n",
    "target_height = 100\n",
    "\n",
    "for row in data.itertuples():\n",
    "    filename = row.img_fName\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = Image.open(img_path)\n",
    "    img = img.crop((row.bbx_xtl, row.bbx_ytl, row.bbx_xbr, row.bbx_ybr))\n",
    "    img = img.resize((target_width, target_height), Image.LANCZOS)\n",
    "    \n",
    "    # Convertir la imagen a escala de grises\n",
    "    img = img.convert(\"L\")\n",
    "    \n",
    "    img = np.array(img) / 255.0\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualización de las clases únicas\n",
    "unique_classes = data['class_label'].unique()\n",
    "num_rows = len(unique_classes) // 3 + 1\n",
    "num_cols = 3\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
    "\n",
    "for i, class_label in enumerate(unique_classes):\n",
    "    class_data = data[data['class_label'] == class_label]\n",
    "    first_image_name = class_data.iloc[0]['img_fName']\n",
    "    image_path = os.path.join(output_folder, first_image_name)\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(f'Clase: {class_label}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "for i in range(len(unique_classes), num_rows * num_cols):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generación de imágenes adicionales\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "max_images = data['class_label'].value_counts().max()\n",
    "data_balanced = pd.DataFrame(columns=['img_fName', 'class_label'])\n",
    "data_balanced = pd.concat([data_balanced, data], ignore_index=True)\n",
    "\n",
    "for class_label in data['class_label'].unique():\n",
    "    class_count = sum(data['class_label'] == class_label)\n",
    "    \n",
    "    if class_count < max_images:\n",
    "        num_new_images = max_images - class_count\n",
    "        class_images = data[data['class_label'] == class_label]['img_fName']\n",
    "        \n",
    "        for i, original_image_name in enumerate(class_images):\n",
    "            img = load_img(os.path.join(output_folder, original_image_name), color_mode='grayscale')\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array.reshape((1,) + img_array.shape)\n",
    "            \n",
    "            i = 0\n",
    "            for batch in datagen.flow(img_array, batch_size=1):\n",
    "                i += 1\n",
    "                if i > num_new_images:\n",
    "                    break\n",
    "                \n",
    "                new_img = array_to_img(batch[0], scale=False)\n",
    "                new_image_name = f'new_image_{original_image_name.split(\".\")[0]}_{i}.jpeg'\n",
    "                new_img.save(os.path.join(output_folder, new_image_name))\n",
    "                \n",
    "                new_data = pd.DataFrame({\n",
    "                    'img_fName': [new_image_name],\n",
    "                    'class_label': [class_label]\n",
    "                })\n",
    "                data_balanced = pd.concat([data_balanced, new_data], ignore_index=True)\n",
    "                \n",
    "            if i >= num_new_images:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mezclar el dataframe\n",
    "data_balanced = shuffle(data_balanced)\n",
    "\n",
    "# Ver la distribución de las clases\n",
    "print(data_balanced['class_label'].value_counts())\n",
    "\n",
    "data_balanced.to_csv('data_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño deseado de las imágenes\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "# 1. Hacer Resize de imágenes:\n",
    "# Ya está realizado en el 'target_size' del generador de datos.\n",
    "\n",
    "# 2. Hacer Data Augmentation:\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# 3. Usar Batches:\n",
    "# Se están usando batches en el código con 'batch_size=32' en los generadores.\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=data_balanced,\n",
    "    directory='procesadas',\n",
    "    x_col='img_fName',\n",
    "    y_col='class_label',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=data_balanced,\n",
    "    directory='procesadas',\n",
    "    x_col='img_fName',\n",
    "    y_col='class_label',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))  \n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))  \n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_model.h5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks=[early_stop, checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica\n",
    "\n",
    "# Precisión\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Pérdida\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validacion con imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mosquito_type(model, img_path):\n",
    "    \"\"\"\n",
    "    Predicts the type of mosquito based on an image.\n",
    "\n",
    "    Parameters:\n",
    "        model : tensorflow.keras.Model\n",
    "            The trained model to use for prediction.\n",
    "        img_path : str\n",
    "            Path to the image file to predict.\n",
    "    \"\"\"\n",
    "    # Load and resize the image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Convert the image to a numpy array and scale the pixel values to [0, 1]\n",
    "    img_array = image.img_to_array(img) / 255.\n",
    "\n",
    "    # Expand dimensions to represent a batch size of 1\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Get the model's prediction\n",
    "    prediction = model.predict(img_batch)\n",
    "\n",
    "    # Get the index of the highest predicted value\n",
    "    predicted_index = np.argmax(prediction)\n",
    "\n",
    "    # Retrieve the class labels from the training data generator\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v, k) for k, v in labels.items())  # flip the key, values in the dictionary\n",
    "\n",
    "    # Get the string label for the prediction\n",
    "    predicted_label = labels[predicted_index]\n",
    "\n",
    "    # Display the prediction\n",
    "    print(f\"Prediction: {predicted_label} ({100*np.max(prediction):.2f}%)\")\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mosquito_type(model, \"prueba.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
